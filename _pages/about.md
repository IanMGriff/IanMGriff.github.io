---
permalink: /
title: "Ian M. Griffith"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm Ian, an AI researcher and Computational Neuroscientist at Meta Reality Labs building human-level perceptual models. I'm finishing my PhD at [Harvard](https://shbtphd.hms.harvard.edu/) and [MIT](https://bcs.mit.edu/) in the [Labratory for Computational Audition](http://mcdermottlab.mit.edu/index.html). Previously, I worked with [Liberty Hamilton](https://www.hamiltonlab.org/), and have a background in Cognitive Science from UC Berkeley, where I worked at the [Redwood Center](https://redwood.berkeley.edu/). I've also been lucky enough to collaborate with the [Flatiron Institute Center for Computational Neuroscience](https://www.simonsfoundation.org/flatiron/center-for-computational-neuroscience/). 

## Research
I'm broadly interested in studying minds and machines to better understand the principles of intelligence, to improve artificial systems and better understand humans. 


### Attention mechanisms & "the cocktail party problem"

![attention model](/images/figure_1.png)

Selective attention has historically been challenging for AI. In our upcoming [Nature Human Behavior (in press)](https://doi.org/10.1101/2025.05.28.656682) paper, we show that neural networks with biologically-inspired attention mechanisms can develop human-like selective attention, using the cocktail party problem as a proving ground. We used these models to predict two novel human behaviors. We also showed that relaxing biological grounding hurt performance, providing some evidence that biological constraints can improve representation learning.

### Modeling music perception

![pitch model](/images/figure_2.png)

Do models trained for music transcription or generation learn human-like features of pitch perception? Early results suggest that relative pitch is an important constraint but not the whole picture. Stay tuned!

