---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm Ian, an AI and computational neuroscientist finishing my PhD at [Harvard](https://shbtphd.hms.harvard.edu/) and [MIT](https://bcs.mit.edu/) in the [Labratory for Computational Audition](http://mcdermottlab.mit.edu/index.html). Previously, I worked with [Liberty Hamilton](https://www.hamiltonlab.org/), and have a background in Cognitive Science from UC Berkeley, where I worked at the [Redwood Center](https://redwood.berkeley.edu/).

Currently, I'm also at Meta Reality Labs as a Research Scientist

### Research
I'm broadly interested in how the human brain translates sounds into perception and creating artificial systems that can do the same. I'm also interested in using computational models of auditory perception to improve hearing assistive devices and audio production technologies.

I'm currently thinking about how deep neural networks can be used to make human-like models of auditory attention. Conversation, listening to music, and other everyday listening tasks rely on a listener's ability to focus on a particular sound source. While natural for many people, this is a surprisingly difficult computational task and it's not fully known how the human brain solves it.

### About

Outside of lab, I like to split my free time between guitar, music production, and Brazilian jiu-jitsu (give it a try if you haven't).

### Contact

If you'd like to reach out, please email me!    

I'm more than happy to talk about the (non-linear) path to grad school, general science, and all things sound and hearing.
